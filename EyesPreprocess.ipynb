{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EyesPreprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s8GgxvKwnI1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBNpWoK8wmqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "0a78bfa1-6963-400b-cddf-2350c0e002c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VM3v2kudKD2"
      },
      "source": [
        "## Library Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQjRt3L5cCmP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from six.moves import cPickle as pickle\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr3CCDHA3gxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "71682638-8918-42dd-ee18-e7c228600da2"
      },
      "source": [
        "!pip install patool"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SGELLMzDgr4"
      },
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/My Drive/ML_Project/dataset_B_Eye_Images.rar\", outdir=\"/content/drive/My Drive/ML_Project\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJLT0OBkFx_k"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/My Drive/Project_19/Dataset/haar cascade files/haarcascade_frontalface_alt.xml')\n",
        "left_eye_cascade = cv2.CascadeClassifier('/content/drive/My Drive/Project_19/Dataset/haar cascade files/haarcascade_lefteye_2splits.xml')\n",
        "right_eye_cascade = cv2.CascadeClassifier('/content/drive/My Drive/Project_19/Dataset/haar cascade files/haarcascade_righteye_2splits.xml')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpSvVitwdhGi"
      },
      "source": [
        "# DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR6Nx9Zjccf3"
      },
      "source": [
        "dir1 = ['/content/drive/My Drive/Project_19/Dataset/Sample images/Open']\n",
        "dir2 = ['/content/drive/My Drive/Project_19/Dataset/Sample images/Closed']\n",
        "dir3 = ['/content/drive/My Drive/Project_19/Dataset/Sample images/Partially Closed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3VZ11Qbd7Il"
      },
      "source": [
        "#Pre processing the data of open eyes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx9dJYb9ccce"
      },
      "source": [
        "def generate_dataset():\n",
        "    dataset = np.ndarray([1231 * 2, 24, 24, 1], dtype='float32')\n",
        "    i = 0\n",
        "    for filename in os.listdir(dir1):\n",
        "      if filename.endswith('.jpg'):\n",
        "        im = cv2.imread(dir1 + '/' + filename)\n",
        "        im = np.dot(np.array(im, dtype='float32'), [[0.2989], [0.5870], [0.1140]]) / 255\n",
        "        dataset[i, :, :, :] = im[:, :, :]\n",
        "        i += 1\n",
        "    labels = np.ones([len(dataset), 1], dtype=int)\n",
        "    return dataset, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abdJsjOuusg4"
      },
      "source": [
        "#Pre processing the data of closed eyes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HCmPGfEccUS"
      },
      "source": [
        "def generate_dataset_closed():\n",
        "    dataset = np.ndarray([1192 * 2, 24, 24, 1], dtype='float32')\n",
        "    i = 0\n",
        "    for filename in os.listdir(dir2):\n",
        "      if filename.endswith('.jpg'):\n",
        "        im = cv2.imread(dir2 + '/' + filename)\n",
        "        im = np.dot(np.array(im, dtype='float32'), [[0.2989], [0.5870], [0.1140]]) / 255\n",
        "        dataset[i, :, :, :] = im[:, :, :]\n",
        "        i += 1\n",
        "    labels = np.zeros([len(dataset), 1], dtype=int)\n",
        "    return dataset, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOFRXlHb_u7x"
      },
      "source": [
        "#Pre processing the data of Partially Closed eyes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRrqI_cRccJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee3be395-9d36-4a2c-ad3a-d83bec800e94"
      },
      "source": [
        "dataset_open, labels_open = generate_dataset()\n",
        "dataset_closed, labels_closed = generate_dataset_closed()\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt5XjPFnu8zV"
      },
      "source": [
        "#Splitting closed eyes dataset into training and testing datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPMzfNglcb7x"
      },
      "source": [
        "split = int(len(dataset_closed) * 0.8)\n",
        "train_dataset_closed = dataset_closed[:split]\n",
        "train_labels_closed = labels_closed[:split]\n",
        "test_dataset_closed = dataset_closed[split:]\n",
        "test_labels_closed = labels_closed[split:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDN-yJMWc3ln"
      },
      "source": [
        "pickle_file = 'closed_eyes.pickle'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1WHnCFEvHIl"
      },
      "source": [
        "#Opening the closed eyes pickle file and dumping it\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYXDayGmc3gf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "266ea55e-4b51-4bb5-c831-64b1ae8df496"
      },
      "source": [
        "try:\n",
        "    f = open(pickle_file, 'wb')\n",
        "    save = {\n",
        "        'train_dataset': train_dataset_closed,\n",
        "        'train_labels': train_labels_closed,\n",
        "        'test_dataset': test_dataset_closed,\n",
        "        'test_labels': test_labels_closed,\n",
        "    }\n",
        "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
        "    f.close()\n",
        "except Exception as e:\n",
        "    print('Unable to save data to', pickle_file, ':', e)\n",
        "    raise\n",
        "\n",
        "statinfo = os.stat(pickle_file)\n",
        "print('Compressed pickle size:', statinfo.st_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compressed pickle size: 5512199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsuAMKNEwAWv"
      },
      "source": [
        "#Splitting the open eyes dataset into training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQg2TDuTc3az"
      },
      "source": [
        "split = int(len(dataset_open) * 0.8)\n",
        "train_dataset_open = dataset_open[:split]\n",
        "train_labels_open = labels_open[:split]\n",
        "test_dataset_open = dataset_open[split:]\n",
        "test_labels_open = labels_open[split:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_t_pKBwHD-"
      },
      "source": [
        "#Open eyes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JpihRIyc3V9"
      },
      "source": [
        "pickle_file = 'open_eyes.pickle'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33etkjfMwNym"
      },
      "source": [
        "#Opening the open eyes pickle file and dumping it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udANMl48c3Ow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "450bc098-5ade-4241-fea4-792dda84390b"
      },
      "source": [
        "try:\n",
        "    f = open(pickle_file, 'wb')\n",
        "    save = {\n",
        "        'train_dataset': train_dataset_open,\n",
        "        'train_labels': train_labels_open,\n",
        "        'test_dataset': test_dataset_open,\n",
        "        'test_labels': test_labels_open,\n",
        "    }\n",
        "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
        "    f.close()\n",
        "except Exception as e:\n",
        "    print('Unable to save data to', pickle_file, ':', e)\n",
        "    raise\n",
        "\n",
        "statinfo = os.stat(pickle_file)\n",
        "print('Compressed pickle size:', statinfo.st_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compressed pickle size: 5692535\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}